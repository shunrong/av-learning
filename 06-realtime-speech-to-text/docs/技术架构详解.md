# 实时语音转文字 - 技术架构详解

## 📐 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                         浏览器端                              │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌──────────────┐      ┌──────────────┐                    │
│  │ 麦克风采集    │─────▶│ MediaRecorder│                    │
│  │getUserMedia │      │   编码Opus    │                    │
│  └──────────────┘      └──────┬───────┘                    │
│                               │                              │
│  ┌──────────────┐             │                              │
│  │ 音量分析      │             │                              │
│  │Web Audio API │             │                              │
│  └──────────────┘             │                              │
│                               ▼                              │
│                        ┌──────────────┐                      │
│                        │  WebSocket   │                      │
│                        │   Client     │                      │
│                        └──────┬───────┘                      │
└───────────────────────────────┼──────────────────────────────┘
                                │
                                │ Binary Audio Data
                                │ + JSON Control Messages
                                │
┌───────────────────────────────┼──────────────────────────────┐
│                         服务器端                              │
├───────────────────────────────┼──────────────────────────────┤
│                               ▼                              │
│                        ┌──────────────┐                      │
│                        │  WebSocket   │                      │
│                        │   Server     │                      │
│                        └──────┬───────┘                      │
│                               │                              │
│                               ▼                              │
│                        ┌──────────────┐                      │
│                        │Mock ASR 服务 │                      │
│                        │ (模拟识别)   │                      │
│                        └──────┬───────┘                      │
│                               │                              │
│                               ▼                              │
│                        ┌──────────────┐                      │
│                        │  识别结果     │                      │
│                        │ text/isFinal │                      │
│                        └──────────────┘                      │
└─────────────────────────────────────────────────────────────┘
```

## 🎤 前端架构

### 1. AudioRecorder 类

**职责**: 管理音频采集、编码、音量检测

```javascript
class AudioRecorder {
  // 核心组件
  - mediaRecorder    // 音频录制器
  - audioStream      // 麦克风音频流
  - audioContext     // 音频上下文
  - analyser         // 音量分析器
  
  // 核心方法
  + init()           // 初始化（获取麦克风权限）
  + start()          // 开始录音
  + stop()           // 停止录音
  + pause()          // 暂停录音
  + resume()         // 恢复录音
  + destroy()        // 释放资源
}
```

**关键技术**:

1. **获取麦克风权限**
```javascript
navigator.mediaDevices.getUserMedia({
  audio: {
    echoCancellation: true,   // 回声消除
    noiseSuppression: true,   // 降噪
    autoGainControl: true,    // 自动增益
    sampleRate: 16000         // 16kHz采样率
  }
})
```

2. **创建录音器**
```javascript
const mediaRecorder = new MediaRecorder(stream, {
  mimeType: 'audio/webm;codecs=opus',  // Opus编码
  audioBitsPerSecond: 16000             // 码率
});

// 每300ms触发一次数据回调
mediaRecorder.start(300);
```

3. **音量分析**
```javascript
const audioContext = new AudioContext();
const analyser = audioContext.createAnalyser();
const source = audioContext.createMediaStreamSource(stream);
source.connect(analyser);

// 获取频域数据
analyser.getByteFrequencyData(dataArray);
const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
```

### 2. SpeechToTextApp 类

**职责**: 应用主逻辑、WebSocket通信、UI控制

```javascript
class SpeechToTextApp {
  // 核心组件
  - ws               // WebSocket连接
  - recorder         // AudioRecorder实例
  - transcriptHistory // 转写历史记录
  
  // 核心方法
  + connectWebSocket()          // 建立连接
  + handleServerMessage()       // 处理服务器消息
  + handleRecognitionResult()   // 处理识别结果
  + start()                     // 开始录音
  + stop()                      // 停止录音
  + exportTranscript()          // 导出文本
}
```

**WebSocket通信流程**:

```
客户端                           服务器
  │                               │
  ├──────── 连接 ────────────────▶│
  │                               │
  │◀────── connected ─────────────┤
  │                               │
  ├──────── start ───────────────▶│
  │                               │
  │◀────── started ───────────────┤
  │                               │
  ├──────── 音频数据 ─────────────▶│
  │                               │
  │                               ├─▶ ASR处理
  │                               │
  │◀────── result ────────────────┤
  │                               │
  ├──────── 音频数据 ─────────────▶│
  │                               │
  │◀────── result ────────────────┤
  │                               │
  ├──────── stop ────────────────▶│
  │                               │
  │◀────── stopped ───────────────┤
  │                               │
```

## 🖥️ 后端架构

### 1. WebSocket服务器

**技术栈**: `ws` 库

```javascript
const wss = new WebSocket.Server({ server });

// 连接管理
wss.on('connection', (ws) => {
  // 分配客户端ID
  const clientId = generateId();
  
  // 存储客户端信息
  clients.set(clientId, {
    ws: ws,
    connectedAt: new Date(),
    audioChunks: 0
  });
  
  // 处理消息
  ws.on('message', handleMessage);
  
  // 处理断开
  ws.on('close', cleanup);
});
```

**消息处理**:

```javascript
async function handleMessage(message) {
  // 1. 尝试解析为JSON（控制消息）
  try {
    const data = JSON.parse(message);
    handleControlMessage(data);
    return;
  } catch (e) {
    // 不是JSON，当作音频数据
  }
  
  // 2. 处理音频数据
  await handleAudioData(message);
}
```

### 2. Mock ASR服务

**职责**: 模拟真实的语音识别服务

```javascript
class MockASRService {
  // 预设文本库
  mockTexts = [
    "今天天气真不错",
    "我正在学习音视频技术",
    // ...
  ];
  
  async processAudio(audioData) {
    // 1. 模拟处理延迟
    await sleep(randomDelay(200, 500));
    
    // 2. 返回随机结果
    return {
      text: getRandomText(),
      isFinal: Math.random() > 0.7,  // 30%概率是最终结果
      confidence: (0.85 + Math.random() * 0.14).toFixed(2),
      timestamp: Date.now()
    };
  }
}
```

**模拟流程**:

```
接收音频数据
    ↓
模拟延迟 (200-500ms)
    ↓
随机选择文本
    ↓
随机决定是否最终结果
    ↓
生成置信度 (0.85-0.99)
    ↓
返回结果
```

## 🔄 数据流转

### 1. 音频数据流

```
麦克风
  ↓
[PCM 原始音频]
  ↓
MediaRecorder (编码)
  ↓
[Opus/WebM 编码音频]
  ↓
WebSocket (传输)
  ↓
服务器接收
  ↓
ASR服务 (识别)
  ↓
文字结果
  ↓
WebSocket (返回)
  ↓
浏览器显示
```

### 2. 控制消息流

```javascript
// 客户端发送
ws.send(JSON.stringify({
  type: 'start'  // 或 'stop', 'ping'
}));

// 服务器响应
ws.send(JSON.stringify({
  type: 'started',
  message: '开始识别'
}));
```

### 3. 识别结果流

```javascript
// 服务器发送
ws.send(JSON.stringify({
  type: 'result',
  data: {
    text: '今天天气真不错',
    isFinal: true,
    confidence: 0.96,
    timestamp: 1234567890
  }
}));

// 客户端处理
handleRecognitionResult(data) {
  this.transcriptHistory.push(data);
  this.appendTranscript(data);
}
```

## 🎨 UI组件架构

### 1. 控制面板

- **开始录音按钮**: 初始化录音器，建立WebSocket连接
- **停止录音按钮**: 停止录音，清理资源
- **暂停/继续按钮**: 切换录音状态
- **清空按钮**: 清除所有转写结果
- **导出按钮**: 下载转写内容为TXT

### 2. 状态显示

- **连接状态**: 实时显示WebSocket连接状态
- **录音状态**: 显示当前状态（准备/录音/暂停/停止）
- **音量条**: 实时显示麦克风音量

### 3. 转写结果区

```html
<div class="transcript-item final">
  <div class="transcript-time">14:30:25</div>
  <div class="transcript-text">今天天气真不错</div>
  <div class="transcript-meta">
    <span class="badge final">最终</span>
    <span class="confidence">置信度: 0.96</span>
  </div>
</div>
```

**样式区分**:
- 临时结果: 灰色背景，灰色左边框
- 最终结果: 蓝色背景，蓝色左边框

## 🔐 安全性考虑

### 1. 权限管理

```javascript
// 检查权限状态
const result = await navigator.permissions.query({ name: 'microphone' });

if (result.state === 'denied') {
  alert('麦克风权限被拒绝');
}
```

### 2. 错误处理

```javascript
try {
  await recorder.init();
} catch (error) {
  if (error.name === 'NotAllowedError') {
    showError('麦克风权限被拒绝');
  } else if (error.name === 'NotFoundError') {
    showError('未找到麦克风设备');
  }
}
```

### 3. 资源清理

```javascript
// 页面卸载时清理
window.addEventListener('beforeunload', () => {
  if (recorder) {
    recorder.destroy();
  }
  if (ws) {
    ws.close();
  }
});
```

## 📊 性能优化

### 1. 音频数据分片

```javascript
// 每300ms发送一次，避免数据过大
mediaRecorder.start(300);
```

### 2. 日志节流

```javascript
// 每10个音频片段输出一次日志
if (client.audioChunks % 10 === 0) {
  console.log(`已接收 ${client.audioChunks} 个音频片段`);
}
```

### 3. UI更新优化

```javascript
// 音量每100ms更新一次
setInterval(updateVolume, 100);

// 自动滚动到最新结果
transcriptEl.scrollTop = transcriptEl.scrollHeight;
```

## 🔄 状态管理

### 客户端状态

```javascript
{
  isConnected: false,      // WebSocket连接状态
  isRecording: false,      // 录音状态
  isPaused: false,         // 暂停状态
  transcriptHistory: [],   // 转写历史
  currentVolume: 0         // 当前音量
}
```

### 服务端状态

```javascript
{
  clients: Map,            // 客户端连接池
  asrService: Object,      // ASR服务实例
  stats: {
    totalRequests: 0,      // 总请求数
    totalAudioChunks: 0,   // 总音频片段数
    startTime: Date        // 启动时间
  }
}
```

## 🚀 扩展点

### 1. 替换为真实ASR

只需实现相同的接口：

```javascript
class RealASRService {
  async processAudio(audioData) {
    // 调用真实的ASR API
    const result = await asrAPI.recognize(audioData);
    
    return {
      text: result.text,
      isFinal: result.is_final,
      confidence: result.confidence,
      timestamp: Date.now()
    };
  }
}
```

### 2. 添加音频缓存

```javascript
class AudioBuffer {
  constructor(maxSize = 10) {
    this.buffer = [];
    this.maxSize = maxSize;
  }
  
  add(audioData) {
    this.buffer.push(audioData);
    if (this.buffer.length > this.maxSize) {
      this.buffer.shift();
    }
  }
  
  getAll() {
    return this.buffer;
  }
}
```

### 3. 断线重连

```javascript
function reconnectWebSocket() {
  let retryCount = 0;
  const maxRetries = 5;
  
  function connect() {
    const ws = new WebSocket(url);
    
    ws.onclose = () => {
      if (retryCount < maxRetries) {
        retryCount++;
        setTimeout(connect, 1000 * retryCount);
      }
    };
  }
  
  connect();
}
```

## 📚 总结

本项目通过分层架构实现了一个完整的实时语音转文字系统：

- **前端层**: MediaRecorder + Web Audio API + WebSocket
- **通信层**: WebSocket双向实时通信
- **服务层**: Mock ASR（可替换为真实服务）
- **展示层**: 实时UI更新 + 结果管理

核心设计原则：
1. **模块化**: 各组件职责清晰，易于维护
2. **可扩展**: Mock服务易于替换为真实AI
3. **高性能**: 实时传输，低延迟反馈
4. **用户友好**: 清晰的状态提示，流畅的交互

